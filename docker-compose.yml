version: "3.11"
services:
  litellm:
    build:
      context: .
      args:
        target: runtime
    # image: ghcr.io/berriai/litellm:main-stable
    #########################################
    ## Uncomment these lines to start proxy with a config.yaml file ##
    volumes:
     - ./config.yaml:/app/config.yaml
     - ./custom_sso.py:/app/custom_sso.py
    command:
     - "--config=/app/config.yaml"
    ##############################################
    ports:
      - "4000:4000"
    environment:
      DATABASE_URL: "postgresql://llmproxy:dbpassword9090@db:5432/litellm"
      STORE_MODEL_IN_DB: "True" # allows adding models to proxy via UI

      # for local debug, comment these out
      PROXY_BASE_URL: "https://api-dev.menlo.ai"
      FRONTEND_URL: "https://platform-dev.menlo.ai"
      COOKIE_DOMAIN: "menlo.ai"
    env_file:
      - .env # Load local .env file
    depends_on:
      - db
    healthcheck:
      test: [ "CMD-SHELL", "wget --no-verbose --tries=1 http://localhost:4000/health/liveliness || exit 1" ]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  frontend:
    build:
      context: ./ui/litellm-dashboard
      args:
        # for local debug, comment these out
        API_URL: "https://api-dev.menlo.ai"
        COOKIE_DOMAIN: "menlo.ai"
    ports:
      - "3000:3000"
    depends_on:
      - litellm

  db:
    image: postgres:16
    restart: always
    container_name: litellm_db
    environment:
      POSTGRES_DB: litellm
      POSTGRES_USER: llmproxy
      POSTGRES_PASSWORD: dbpassword9090
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data # Persists Postgres data across container restarts
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -d litellm -U llmproxy"]
      interval: 1s
      timeout: 5s
      retries: 10

volumes:
  postgres_data:
    name: litellm_postgres_data # Named volume for Postgres data persistence
